# Assignment 05 â€” Linear Regression From Scratch
 Overview

In this assignment, Linear Regression is implemented manually using only NumPy, without using Scikit-learn.
This helps in understanding the mathematical foundation behind:

Loss function (MSE)

Gradient Descent optimization

Weight updates

Model predictions

Training loop

 What I Learned

Derivation of cost function for linear regression

How gradients work

How to implement batch gradient descent

Importance of learning rate

Plotting loss vs iterations

Evaluating model performance manually

 Mathematical Concepts Used
 Hypothesis
ğ‘¦
^
=
ğ‘š
ğ‘¥
+
ğ‘
y
^
	â€‹

=mx+c
 Loss Function
ğ½
=
1
2
ğ‘š
âˆ‘
(
ğ‘¦
âˆ’
ğ‘¦
^
)
2
J=
2m
1
	â€‹

âˆ‘(yâˆ’
y
^
	â€‹

)
2
 Gradients
âˆ‚
ğ½
âˆ‚
ğ‘š
=
âˆ’
1
ğ‘š
âˆ‘
ğ‘¥
(
ğ‘¦
âˆ’
ğ‘¦
^
)
âˆ‚m
âˆ‚J
	â€‹

=âˆ’
m
1
	â€‹

âˆ‘x(yâˆ’
y
^
	â€‹

)
âˆ‚
ğ½
âˆ‚
ğ‘
=
âˆ’
1
ğ‘š
âˆ‘
(
ğ‘¦
âˆ’
ğ‘¦
^
)
âˆ‚c
âˆ‚J
	â€‹

=âˆ’
m
1
	â€‹

âˆ‘(yâˆ’
y
^
	â€‹

)
 Update Rule
ğ‘š
=
ğ‘š
âˆ’
ğ›¼
âˆ‚
ğ½
âˆ‚
ğ‘š
m=mâˆ’Î±
âˆ‚m
âˆ‚J
	â€‹

ğ‘
=
ğ‘
âˆ’
ğ›¼
âˆ‚
ğ½
âˆ‚
ğ‘
c=câˆ’Î±
âˆ‚c
âˆ‚J
	â€‹

Technologies Used

Python 3.x

NumPy

Pandas (optional)

Matplotlib

Folder Structure
Assignment-05-Linear-Regression-From-Scratch/
â”‚â”€â”€ Assignment-05.ipynb
â”‚â”€â”€ dataset.csv       (optional)
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt

 How to Run
1. Install dependencies
pip install -r requirements.txt

2. Launch notebook
jupyter notebook Assignment-05.ipynb

 Expected Outputs

Gradient Descent implementation

Graph of Loss vs Iterations

Learned slope m and intercept c

Predicted values vs Actual values plot
